Having set up the basics of the time-dependent perturbation theory for simple oscillating,
or what we sometimes call harmonic perturbations, we're now going to derive an extremely useful
rule in quantum mechanics. This is generally known as Fermi's golden rule. This is a simple
formula that works for a very broad range of problems and gives us a simple answer for
transition rates, such as optical absorption and other kinds of interactions involving
oscillating fields, such as interactions with vibrations or with acoustic fields and solid
materials, as we said, often described as phonon scattering. Fermi's golden rule applies
whenever we have got a dense set of possible final states in a system which is a very common
situation in many materials.
So now then, we're going to consider the case only associated with absorption presuming
we're starting in a lower energy state and transitioning to a higher energy one. The
treatment of the stimulated emission case would be essentially identical with the energies
of the states reversed. However, here we're going to look at the absorption case.
Then we have this equation from our previous derivation, leaving only the absorption term
in here, which resonates when omega is approximately equal to omega jm-- the separation between
the jth state and the mth state in energy divided by h-bar. So analyzing the case of
a transition between one state and exactly one other state using this approach turns
out to have some formal difficulties.
The problem is as we let the time t naught become arbitrarily large, the sinc squared
term becomes arbitrarily sharp in omega. Unless the frequency is exactly correct, then we
will get no absorption. We can solve this problem with a more sophisticated analysis
involving what's called density matrices, but we're not going to be able to do that
here. That will take some more setup. But that allows "widths" to the absorption lines,
rather than just the sinc function becoming arbitrarily sharp. And that gets us out of
this problem with a singularity here.
If we were to go to the density matrix form, we would end up with more of a Lorentzian
function, rather than a sinc squared function. So the Lorentzian function looks like this.
And this is a mathematical form of a Lorentzian function. And it has a width, a half-width,
for example, of one over this parameter T2 here. So the total width at half maximum would
be 2 over this T2 parameter.
There's a physical meaning to the T2 parameter, once we do the density matrix theory. And
that is that it's essentially the time between the scattering that the system encounters,
which could be, for example, collisions with other atoms. That's something we've not put
into our theory so far, and so we, therefore, don't get rid of our singularity. But with
the density matrix formalism, we can put in that effect, and their singularity disappears,
and we get this kind of Lorentzian function instead. However for the moment, we're not
going to make this particular change, because there is still something quite useful we can
do in the current form.
We can incidentally rationalize this Lorentzian form here, even though we're not going to
go through the physics. We can rationalize why we don't just get an arbitrarily sharp
function based on an energy-time uncertainty relation kind of argument. And this is an
approximate argument, but it gives a sense of why lines don't get arbitrarily sharp.
If a system only exists in its original form for some time T2, with T2 be in the standard
way of notating this particular phenomenon in the density matrix theory, then we should
expect that the energy of the transition is only defined to some energy within something
like h-bar over T2, or in frequency, angular frequency here, to within something like 1
over T2.
Incidentally, if you followed through the precise uncertainty principle arguments, there
would be another factor of 2 in here, but this is only a rough argument. So the idea
is that physically in the way we are looking at the problem at the moment, we're being
a little unphysical, because we haven't put in the fact that all sorts of systems are
going to suffer collisions of one kind or another, and from something like an uncertainty
principle argument, no line is going to get arbitrarily sharp, because that would mean
its energy was arbitrarily well defined. And if it has some lifetime kind of effect associated
with it, that simply physically won't happen.
Anyway, as I said, we're not going to do this Lorentzian analysis at the moment, but that
is still something useful we can do even with the analysis we have. The analysis we have
so far does turn out to work quite well, if we're thinking about dense sets of possible
transitions. So a major class of problems then can be analyzed using our approach.
Suppose, we have not one possible transition with a very specific energy difference h-bar
omega jm, but a dense set of transitions near this photon energy h-bar omega. So something
like this here. Here's our photon energy, this magnitude here. And we find that in our
system maybe we have many different atoms, and they might have slightly different energies
associated with their transitions here. And instead of having one transition, we have
a dense set of possible transitions, each with slightly different energies. But presumably,
they all have essentially identical matrix elements, they have essentially identical
strengths for these transitions, if we get the frequency right.
Well, this kind of situation occurs quite routinely in solid materials, for example.
So not just one transition energy, but a dense set of possible transitions, with somewhat
different energies. We presume that this set of possible transitions then is very dense
in frequency or energy, and so we could talk about a density per unit energy near the photon
energy h-bar omega. We could call that density g sub J of h-bar omega.
That is that within some range here of possible photon energies, for example, so with photon
energies anywhere from this amount all the way up to, say, this amount here, separated
by some amount of energy, delta E, then we would find a total of gJ of h-bar omega times
delta E. So gJ of h-bar omega is the density of possible transitions in energy, and then
we multiply that by a small amount of energy to get the total number of transitions within
that energy range.
gJ of h-bar omega is sometimes known as a joint density of states since it refers to
transitions between states. In distinction to just a density of states, which would just
be density of particular energy states, not of transition energies that we're talking
about here. So if we're talking about dense sense of possible transitions, we can add
up the probabilities for absorbing transitions and obtain a total probability of absorption
by this set of transitions of this amount here.
So we're summing up over all the possible transitions, or what we are actually going
to do here is instead of doing a sum, we're going to do an integral over this density
of transitions and, of course, a little increment of energy here. So it could have been a sum
with gJ of h-bar omega jm times delta E. But what we're doing instead is an integral with
the infinitesimal in here.
So this would be us adding up the probabilities for all the absorbing transitions within some
given range of energies or photon energies, or energy separations as a way of looking
at it. So what we're doing here is adding up the probabilities for all the possible
transitions that are near photon energy frequency omega. And we're using a density of transitions
in here.
Approximately speaking, we're presuming that this density is constant over small energy
ranges. So again, this is a density of possible transitions in the system, a density in energy
range. And presumably then this sinc squared term that we have here is narrow in omega
jm. We're presuming that t0 is quite large.
Hence, this density, joint density of states here, is approximately constant everywhere
in our integral, so we can take it out the front. And therefore, we're going to obtain
just a factor gJ of h-bar omega, because, approximately speaking, omega jm for everywhere
within this integral that we're doing here, will be approximately h-bar omega. And so
as long as this density of state is approximately constant over some range of energies, then
we can just take it out as this constant.
So formally changing the variable in this integral just for mathematical purposes, then
we can perform this integral, and our integral just turns into a purely mathematical one.
And this particular integral is one that we can perform. The result of that particular
mathematical integral is just pi.
And so as a result, we'll obtain a total probability of making some transition that is given by
the following expression. So 2pi times t naught-- that's the length of time we have our perturbation
on for-- divided by h-bar, multiplied by the modulus squared of this matrix element between
the initial and final states. And remember, in here and our electromagnetic case, this
was just the electronic charge times the magnitude of the electric field that's oscillating,
E times position z, which is an operator in here.
So this is our formula for the total probability of making some transition as a result of having
this perturbation on for time t nought. And it's a meaningful kind of calculation. We've
managed to get rid of that infinitely sharp spike concept that was bothering us before.
And that's because we've got a dense set of transitions we are working with.
Now, we can see that we are able to calculate a total probability of making some transition.
It is proportional to the time for which the perturbation has been applied. And so therefore,
we can deduce a transition rate. That is a rate of absorption here of photons. That is
basically that probability that we just calculated divided by the time for which the perturbation
had been applied. So this will give us the rate of absorption of photons,
the probability that a photon would be absorbed in a total amount of time t nought, but divided
by that time t nought. So that gives a rate of absorption of photons, which we call W.
And here we have then a nice simple formula for that, whenever we've got a dense set of
possible transitions.
So this result is called Fermi's golden rule. And that's because Fermi actually popularized
this. This rule was also derived by Dirac, when he was working on the theory of optics
and quantum mechanics. This turns out to be one of the most useful results of time-dependent
perturbation theory. It's something that we use in many different situations. And for
example, we can use it to calculate optical properties, like optical absorption spectra
of solids, which typically have very dense sets of possible transitions.
And we can also apply it to many other problems involving simple harmonic perturbations. For
example, problems involving phonons, which are acoustic vibrations inside solids and
which often give scattering processes that we see when we're working with electrons.
We can state Fermi's golden rule in alternative way, which is using Dirac's delta function.
This is merely a formal change compared to what we were looking at. And in this case,
we are using a small w here. And this is the transition rate between state m and state
j. And of course, it does have this formal difficulty that it has a sharply-spiked function
here, which is what the delta function is.
But this would give us formally in a mathematical sense the transition rates between states
m and j of the system. And as I said, this is the Dirac delta function, which is an infinitely
high and sharp spike, that nonetheless has unit area. So that's a mathematical concept
that helps us write something down in a compact form here, although you have to be careful
in understanding what you can and cannot do with Dirac delta functions.
Then, if we use this formalism, the total transition rate involving all the possible
similar transitions in the neighborhood of this transition energy we're interested in,
the photon energy here, is then formally the integral of this wgm, small w, with the density
of states, and dh bar omega jm. This is actually the same as the formula we were looking at
a minute ago, it's just a different mathematical way of writing it. And you'll often see Fermi's
golden rule stated this way.