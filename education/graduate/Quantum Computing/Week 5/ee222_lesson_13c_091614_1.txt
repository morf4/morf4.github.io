Now we're going to introduce the Dirac bra-ket notation. And as I said, this is really a
pun on the word bracket but we're splitting it into two parts. This is a beautiful and
very elegant notation for doing linear algebra.
The first part of the Dirac bra-ket notation is this object here, which we call a ket.
And this refers to our column vector that we've been drawing of the elements of the
function at all of the different values of the argument. That's one way to think of this
ket. So we can think of this ket then as a column vector representing a function.
For the case then of our function f of x, one way to find the ket then explicitly would
be to write it out like this. So here are the values of the function here, or the limit
of this as delta x tends towards zero. Here we've put this square root of delta x in here
for normalization but mostly actually we'll manage to get rid of that and save that little
confusion. But we could define our ket as this vector here. This vector is still our
list of numbers representing our function.
We can similarly define the bra version of the same function. And this refers to a row
vector. So instead of a column, a row. And so, therefore this bra version would represent
the same function-- we've still got our delta x's in here and the square roots. And we've
got f of x1. But note that we have the complex conjugates in here. And again we mean the
limit of this as delta x goes to zero.
So the bra vector represents the same function, but it's a row vector version. And we write
down the complex conjugates of all of the values of the function at each of the different
points, the arguments x1, x2, and x3. So note then, in our row vector, as I said, we take
the complex conjugate of all of these values.
Note that this bra here refers to exactly the same function as the ket did. These are
just different ways of writing the same function. And it might seem a little odd that we put
the complex conjugate in here, but that turns out to be very useful as we will see.
Now this vector with numbers a1 complex conjugated, a2 complex conjugated, and a3 complex conjugated,
and so on, is something that has various different possible names. And these include the Hermitian
adjoint, the Hermitian transpose, the Hermitian conjugate, or possibly just the adjoint of
this other vector with the non-complex conjugate elements in it and in a column rather than
a row. So this row vector here with the complex conjugated elements is the Hermitian adjoint
of this column vector with the non-complex conjugated elements in it.
And the common notation used to indicate the Hermitian adjoint rather than always having
to write out the rows, and the columns, and the complex conjugates, and so on, is to use
this character, a dagger, as a superscript. So we could say that the Hermitian adjoint
of this column vector is this row vector with the complex conjugated elements in it.
Forming the Hermitian adjoint is like reflecting about a 45 degree line, a minus 45 degree
line if you like to be strict about it, and then taking the complex conjugate of all the
elements. So for example, here we are performing this Hermitian adjoint operation on this column
vector. It's like taking this column vector and reflecting it about this line here and
taking the complex conjugate when you do it to get this row vector here-- this is a result
the row vector-- so the Hermitian adjoint here, of this column vector is just reflecting
about that 45 degree line and taking the complex conjugate to get the row vector.
Now the bra is the Hermitian adjoint of the ket. And vice versa, the other we around as
well. So if we take this ket factor here, and take the Hermitian adjoint, that's the
same thing as the bra vector for the same function. And similarly, if we take the bra
vector and take the Hermitian adjoint of that, we get the ket vector for the same function.
The Hermitian adjoint of the Hermitian adjoint just gets us back to where we started. So
if we take the Hermitian adjoint of the Hermitian adjoint of this column vector, that's the
same thing as saying the Hermitian joint of this row vector with the complex conjugated
elements because that is just another way of writing out this column vector here, Hermitian
adjoint. And then we take the Hermitian adjoint of the whole thing and we get back to where
we started because we're still just reflecting about that 45 degree line and taking the complex
conjugate.
So that maps a1 star back onto the a1 and so on. Bra-ket notation for functions is very
useful when we consider f of x as a vector. And following our previous result and adding
the bra-ket notation here, we can write out this integral, which we had decided was the
product of this bra vector and this ket vector in a shorthand notation. Of course we could
write out this product here as a summation of each of these values, f star of x n times
f of x n, and we've got our root delta x's in here to keep the normalization correct,
and summing over n.
But in the bra-ket notation we simply write that as this object here, with the ket vector
on the right and the bra vector on the left. And of course the strict equality here of
this integral and this result of a summation, or with this shorthand notation down here,
this applies in the limit as delta x goes to zero, of course.
Now note that the use of the bra-ket notation here eliminates the need to write an integral
or something. If we merely use this here we don't have to bother writing out any of these
other forms. This is a shorthand notation for writing these. And note that of course
that when we do a vector multiplication, the sum over each of these products is implicit
in the vector multiplication. So this saves us the bother of explicitly writing down a
sum.
We think of this as a column vector and a row vector multiplying one another. So the
summation that we've written explicitly here is implicit because we're just multiplying
two vectors. I mean though we have to do that sum when we do that.
Note that the shorthand for the vector product of the bra and ket vectors has got only one
line in it usually when we write it down. We could write it like this, with some sort
of multiplication sign in the middle, or we could even miss that out. But we typically
don't bother to draw the two lines in the middle that we could draw. It is usually omitted
but it would make no difference if we left it in. It just saves us some pencil lead not
to bother to write it down.
And this notation is also useful when we're doing integrals of two different functions--
so for example, if we were performing this integral, a kind of overlap integral of f
of x and g of x here. So in those integrals we often take the complex conjugate. So if
that was the case, this integral here, we could write it in this column vector row vector
form here, or we could write it in this summation form. But we could also just write it in this
shorthand form with the bra-ket notation.
Now a very important concept in these spaces that we're working with is what's called the
inner product. In general this kind of product that we've just written down here is called
an inner product in linear algebra. So really this format here is the Dirac bra-ket notation
version of the inner product. The geometric vector dot product is also an inner product.
The bra-ket product, as I said here, is an inner product. The overlap integral that we've
written down here is an inner product. And this idea of an inner product has a special
meaning that we will get to here.
The inner product is inner because it takes two big things, vectors, and turns them into
just a number. It's a smaller entity if you like. In the Dirac notation for this inner
product here, the notation gives you a kind of inner feel-- there's a kind of enclosure
going on here, an inner feel to this product.
And later on we'll see what an outer product is by the way. And this special parenthesis,
as I said, gives a kind of closed look to the whole object. Whether you see it that
way or not is not important, but it's sort of something you get used to when you're working
with the Dirac notation. You start to see these things as a "yes, that's a number".
It's just enclosed here in these brackets, these special brackets.