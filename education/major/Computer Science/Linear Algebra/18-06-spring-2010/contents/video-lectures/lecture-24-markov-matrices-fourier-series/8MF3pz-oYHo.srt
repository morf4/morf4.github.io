1
00:00:06,000 --> 00:00:09,000
-- two, one and -- okay.

2
00:00:09,000 --> 00:00:16,000
Here is a lecture on the
applications of eigenvalues and,

3
00:00:16,000 --> 00:00:21,550
if I can -- so that will be
Markov matrices.

4
00:00:21,550 --> 00:00:28,000
I'll tell you what a Markov
matrix is, so this matrix A will

5
00:00:28,000 --> 00:00:35,000
be a Markov matrix and I'll
explain how they come in

6
00:00:35,000 --> 00:00:38,000
applications.

7
00:00:38,000 --> 00:00:43,000
And -- and then if I have time,
I would like to say a little

8
00:00:43,000 --> 00:00:48,000
bit about Fourier series,
which is a fantastic

9
00:00:48,000 --> 00:00:51,000
application of the projection
chapter.

10
00:00:51,000 --> 00:00:52,000
Okay.

11
00:00:52,000 --> 00:00:54,000
What's a Markov matrix?

12
00:00:54,000 --> 00:00:58,810
Can I just write down a typical
Markov matrix,

13
00:00:58,810 --> 00:01:01,000
say .1, .2, .7,
.01,

14
00:01:01,000 --> 00:01:05,000
.99 0, let's say,
.3, .3, .4.

15
00:01:05,000 --> 00:01:05,000
Okay.
There's a -- a totally just
invented Markov matrix.

16
00:01:11,000 --> 00:01:14,000
What makes it a Markov matrix?

17
00:01:14,000 --> 00:01:19,000
Two properties that this --
this matrix has.

18
00:01:19,000 --> 00:01:27,000
So two properties are -- one,
every entry is greater equal

19
00:01:27,000 --> 00:01:28,000
zero.

20
00:01:28,000 --> 00:01:32,000
All entries greater than or
equal to zero.

21
00:01:32,000 --> 00:01:37,000
And, of course,
when I square the matrix,

22
00:01:37,000 --> 00:01:42,000
the entries will still be
greater/equal zero.

23
00:01:42,000 --> 00:01:48,000
I'm going to be interested in
the powers of this matrix.

24
00:01:48,000 --> 00:01:53,000
And this property,
of course, is going to -- stay

25
00:01:53,000 --> 00:01:54,000
there.

26
00:01:54,000 --> 00:01:59,050
It -- really Markov matrices
you'll see are connected to

27
00:01:59,050 --> 00:02:02,740
probability ideas and
probabilities are never

28
00:02:02,740 --> 00:02:03,000
negative.

29
00:02:03,000 --> 00:02:08,000
The other property -- do you
see the other property in there?

30
00:02:08,000 --> 00:02:14,000
If I add down the columns,
what answer do I get?

31
00:02:14,000 --> 00:02:14,810
One.

32
00:02:14,810 --> 00:02:18,000
So all columns add to one.

33
00:02:18,000 --> 00:02:21,210
All columns add to one.

34
00:02:21,210 --> 00:02:29,000
And actually when I square the
matrix, that will be true again.

35
00:02:29,000 --> 00:02:36,000
So that the powers of my matrix
are all Markov matrices,

36
00:02:36,000 --> 00:02:43,000
and I'm interested in,
always, the eigenvalues and the

37
00:02:43,000 --> 00:02:46,550
eigenvectors.

38
00:02:46,550 --> 00:02:49,000
And this question of steady
state will come up.

39
00:02:49,000 --> 00:02:54,000
You remember we had steady
state for differential equations

40
00:02:54,000 --> 00:02:54,000
last time?
When -- what was the steady
state -- what was the

41
00:02:58,000 --> 00:02:59,000
eigenvalue?

42
00:02:59,000 --> 00:03:03,000
What was the eigenvalue in the
differential equation case that

43
00:03:03,000 --> 00:03:05,000
led to a steady state?

44
00:03:05,000 --> 00:03:08,000
It was lambda equals zero.

45
00:03:08,000 --> 00:03:12,000
When -- you remember that we
did an example and one of the

46
00:03:12,000 --> 00:03:17,000
eigenvalues was lambda equals
zero, and that -- so then we had

47
00:03:17,000 --> 00:03:22,000
an E to the zero T,
a constant one -- as time went

48
00:03:22,000 --> 00:03:24,000
on, there that thing stayed
steady.

49
00:03:24,000 --> 00:03:30,000
Now what -- in the powers case,
it's not a zero eigenvalue.

50
00:03:30,000 --> 00:03:34,000
Actually with powers of a
matrix, a zero eigenvalue,

51
00:03:34,000 --> 00:03:37,000
that part is going to die right
away.

52
00:03:37,000 --> 00:03:40,000
It's an eigenvalue of one
that's all important.

53
00:03:40,000 --> 00:03:45,000
So this steady state will
correspond -- will be totally

54
00:03:45,000 --> 00:03:49,000
connected with an eigenvalue of
one and its eigenvector.

55
00:03:49,000 --> 00:03:52,000
In fact, the steady state will
be

56
00:03:52,000 --> 00:03:56,000
the eigenvector for that
eigenvalue.

57
00:03:56,000 --> 00:03:56,000
Okay.
So that's what's coming.

58
00:03:58,000 --> 00:04:02,000
Now, for some reason then that
we have to see,

59
00:04:02,000 --> 00:04:06,000
this matrix has an eigenvalue
of one.

60
00:04:06,000 --> 00:04:10,000
This property,
that the columns all add to one

61
00:04:10,000 --> 00:04:15,000
-- turns out -- guarantees that
one is an eigenvalue,

62
00:04:15,000 --> 00:04:20,000
so that you can
actually find the eigenvalue --

63
00:04:20,000 --> 00:04:24,000
find that eigenvalue of a Markov
matrix without computing any

64
00:04:24,000 --> 00:04:28,000
determinants of A minus lambda I
-- that matrix will have an

65
00:04:28,000 --> 00:04:31,000
eigenvalue of one,
and we want to see why.

66
00:04:31,000 --> 00:04:36,000
And then the other thing is --
so the key points -- let me --

67
00:04:36,000 --> 00:04:39,000
let me write these underneath.

68
00:04:39,000 --> 00:04:46,110
The key points are -- the key
points are lambda equal one is

69
00:04:46,110 --> 00:04:47,000
an eigenvalue.

70
00:04:47,000 --> 00:04:53,000
I'll add in a little -- an
additional -- well,

71
00:04:53,000 --> 00:04:58,140
a thing about eigenvalues --
key point two,

72
00:04:58,140 --> 00:05:04,000
the other eigenval- values --
all other eigenvalues are,

73
00:05:04,000 --> 00:05:08,000
in magnitude,
smaller than one -- in absolute

74
00:05:08,000 --> 00:05:11,000
value, smaller than one.

75
00:05:11,000 --> 00:05:16,000
Well, there could be some
exceptional case when -- when an

76
00:05:16,000 --> 00:05:21,000
eigen -- another eigenvalue
might have magnitude equal one.

77
00:05:21,000 --> 00:05:25,000
It never has an eigenvalue
larger than one.

78
00:05:25,000 --> 00:05:30,000
So these two facts --
somehow we ought to -- linear

79
00:05:30,000 --> 00:05:32,000
algebra ought to tell us.

80
00:05:32,000 --> 00:05:36,000
And then, of course,
linear algebra is going to tell

81
00:05:36,000 --> 00:05:40,000
us what the -- what's -- what
happens if I take -- if -- you

82
00:05:40,000 --> 00:05:45,000
remember when I solve -- when I
multiply by A time after time

83
00:05:45,000 --> 00:05:51,000
the K-th thing is A to the K u0
and I'm asking what's special

84
00:05:51,000 --> 00:05:57,000
about this -- these powers of A,
and very likely the quiz will

85
00:05:57,000 --> 00:06:03,000
have a problem to computer s- to
computer some powers of A or --

86
00:06:03,000 --> 00:06:06,000
or applied to an initial vector.

87
00:06:06,000 --> 00:06:09,000
So, you remember the general
form?

88
00:06:09,000 --> 00:06:13,000
The general form is that
there's

89
00:06:13,000 --> 00:06:17,000
some amount of the first
eigenvalue to the K-th power

90
00:06:17,000 --> 00:06:21,000
times the first eigenvector,
and another amount of the

91
00:06:21,000 --> 00:06:26,000
second eigenvalue to the K-th
power times the second

92
00:06:26,000 --> 00:06:27,000
eigenvector and so on.

93
00:06:27,000 --> 00:06:32,000
A -- just -- my conscience
always makes me say at least

94
00:06:32,000 --> 00:06:36,000
once per lecture that this
requires

95
00:06:36,000 --> 00:06:40,920
a complete set of eigenvectors,
otherwise we might not be able

96
00:06:40,920 --> 00:06:45,000
to expand u0 in the eigenvectors
and we couldn't get started.

97
00:06:45,000 --> 00:06:48,000
But once we're started with u0
when K is zero,

98
00:06:48,000 --> 00:06:51,000
then every A brings in these
lambdas.

99
00:06:51,000 --> 00:06:56,000
And now you can see what the
steady state is going to be.

100
00:06:56,000 --> 00:07:01,000
If lambda one is one -- so
lambda one equals one to the

101
00:07:01,000 --> 00:07:06,000
K-th power and these other
eigenvalues are smaller than one

102
00:07:06,000 --> 00:07:12,000
-- so I've sort of scratched
over the equation there to -- we

103
00:07:12,000 --> 00:07:16,000
had this term,
but what happens to this term

104
00:07:16,000 --> 00:07:20,000
-- if the lambda's smaller than
one,

105
00:07:20,000 --> 00:07:24,000
then the -- when -- as we take
powers, as we iterate as we --

106
00:07:24,000 --> 00:07:27,380
as we go forward in time,
this goes to zero,

107
00:07:27,380 --> 00:07:27,000
right?

108
00:07:27,000 --> 00:07:31,000
Can I just -- having scratched
over it, I might as well scratch

109
00:07:31,000 --> 00:07:32,000
further.

110
00:07:32,000 --> 00:07:36,000
That term and all the other
terms are going to zero because

111
00:07:36,000 --> 00:07:42,000
all the other eigenvalues
are smaller than one and the

112
00:07:42,000 --> 00:07:49,000
steady state that we're
approaching is just -- whatever

113
00:07:49,000 --> 00:07:57,000
there was -- this was -- this
was the -- this is the x1 part

114
00:07:57,000 --> 00:08:05,000
of un- of the initial condition
u0 -- is the steady state.

115
00:08:05,000 --> 00:08:09,000
This much we know from general
-- from -- you know,

116
00:08:09,000 --> 00:08:10,000
what we've already done.

117
00:08:10,000 --> 00:08:14,760
So I want to see why -- let's
at least see number one,

118
00:08:14,760 --> 00:08:16,000
why one is an eigenvalue.

119
00:08:16,000 --> 00:08:21,100
And then there's actually -- in
this chapter we're interested

120
00:08:21,100 --> 00:08:25,000
not only in eigenvalues,
but also eigenvectors.

121
00:08:25,000 --> 00:08:30,000
And there's something special
about the eigenvector.

122
00:08:30,000 --> 00:08:33,000
Let me write down what that is.

123
00:08:33,000 --> 00:08:39,000
The eigenvector x1 -- x1 is the
eigenvector and all its

124
00:08:39,000 --> 00:08:44,000
components are positive,
so the steady state is

125
00:08:44,000 --> 00:08:47,000
positive, if the start was.

126
00:08:47,000 --> 00:08:52,000
If the start was -- so -- well,
actually,

127
00:08:52,000 --> 00:08:57,000
in general, I -- this might
have a -- might have some

128
00:08:57,000 --> 00:09:02,670
component zero always,
but no negative components in

129
00:09:02,670 --> 00:09:04,000
that eigenvector.

130
00:09:04,000 --> 00:09:04,000
Okay.
Can I come to that point?

131
00:09:07,000 --> 00:09:12,000
How can I look at that matrix
-- so that was just an example.

132
00:09:12,000 --> 00:09:19,000
How could I be sure -- how can
I see that a matrix --

133
00:09:19,000 --> 00:09:24,000
if the columns add to zero --
add to one, sorry -- if the

134
00:09:24,000 --> 00:09:29,000
columns add to one,
this property means that lambda

135
00:09:29,000 --> 00:09:32,000
equal one is an eigenvalue.

136
00:09:32,000 --> 00:09:32,000
Okay.
So let's just think that
through.

137
00:09:35,000 --> 00:09:41,870
What I saying about -- let me
ca- let me look at A,

138
00:09:41,870 --> 00:09:47,340
and if I believe that one is an
eigenvalue, then I should be

139
00:09:47,340 --> 00:09:52,000
able to subtract off one times
the identity and then I would

140
00:09:52,000 --> 00:09:57,000
get a matrix that's,
what, -.9, -.01 and -.6 -- wh-

141
00:09:57,000 --> 00:10:02,000
I took the ones away and the
other parts, of course,

142
00:10:02,000 --> 00:10:08,000
are still what they were,
and this is still .2 and .7 and

143
00:10:08,000 --> 00:10:13,000
-- okay, what's -- what's up
with this matrix now?

144
00:10:13,000 --> 00:10:18,000
I've shifted the matrix,
this Markov matrix by one,

145
00:10:18,000 --> 00:10:23,200
by the identity,
and what do I want to prove?

146
00:10:23,200 --> 00:10:28,000
I -- what is it that I believe
this matrix -- about this

147
00:10:28,000 --> 00:10:30,000
matrix?

148
00:10:30,000 --> 00:10:32,000
I believe it's singular.

149
00:10:32,000 --> 00:10:36,000
Singular will -- if A minus I
is singular, that tells me that

150
00:10:36,000 --> 00:10:38,000
one is an eigenvalue,
right?

151
00:10:38,000 --> 00:10:42,000
The eigenvalues are the numbers
that I subtract off -- the

152
00:10:42,000 --> 00:10:47,000
shifts -- the numbers that I
subtract from the diagonal -- to

153
00:10:47,000 --> 00:10:48,000
make it singular.

154
00:10:48,000 --> 00:10:51,000
Now why is that matrix
singular?

155
00:10:51,000 --> 00:10:56,000
I -- we could compute its
determinant, but we want to see

156
00:10:56,000 --> 00:11:00,000
a reason that would work for
every Markov matrix not just

157
00:11:00,000 --> 00:11:03,000
this particular random example.

158
00:11:03,000 --> 00:11:05,000
So what is it about that
matrix?

159
00:11:05,000 --> 00:11:11,000
Well, I guess you could look at
its columns now -- what

160
00:11:11,000 --> 00:11:14,000
do they add up to?

161
00:11:14,000 --> 00:11:15,000
Zero.

162
00:11:15,000 --> 00:11:24,000
The columns add to zero,
so all columns -- let me put

163
00:11:24,000 --> 00:11:33,000
all columns now of -- of -- of A
minus I add to zero,

164
00:11:33,000 --> 00:11:42,000
and then I want to realize that
this means A minus I is

165
00:11:42,000 --> 00:11:44,000
singular.

166
00:11:44,000 --> 00:11:44,000
Okay.
Why?

167
00:11:45,000 --> 00:11:52,000
So I could I --
you know, that could be a quiz

168
00:11:52,000 --> 00:11:55,000
question, a sort of theoretical
quiz question.

169
00:11:55,000 --> 00:11:59,000
If I give you a matrix and I
tell you all its columns add to

170
00:11:59,000 --> 00:12:02,000
zero, give me a reason,
because it is true,

171
00:12:02,000 --> 00:12:04,000
that the matrix is singular.

172
00:12:04,000 --> 00:12:04,350
Okay.

173
00:12:04,350 --> 00:12:07,000
I guess actually -- now what --
I think of -- you know,

174
00:12:07,000 --> 00:12:11,000
I'm thinking of two or three
ways to

175
00:12:11,000 --> 00:12:12,060
see that.

176
00:12:12,060 --> 00:12:13,000
How would you do it?

177
00:12:13,000 --> 00:12:18,000
We don't want to take its
determinant somehow.

178
00:12:18,000 --> 00:12:24,000
For the matrix to be singular,
well, it means that these three

179
00:12:24,000 --> 00:12:26,000
columns are dependent,
right?

180
00:12:26,000 --> 00:12:32,000
The determinant will be zero
when those three columns are

181
00:12:32,000 --> 00:12:33,120
dependent.

182
00:12:33,120 --> 00:12:37,000
You see, we're --
we're at a point in this

183
00:12:37,000 --> 00:12:40,000
course, now, where we have
several ways to look at an idea.

184
00:12:40,000 --> 00:12:44,000
We can take the determinant --
here we don't want to.

185
00:12:44,000 --> 00:12:47,390
B- but we met singular before
that -- those columns are

186
00:12:47,390 --> 00:12:48,000
dependent.

187
00:12:48,000 --> 00:12:50,000
So how do I see that those
columns are dependent?

188
00:12:50,000 --> 00:12:52,000
They all add to zero.

189
00:12:52,000 --> 00:12:56,000
Let's see, whew -- well,
oh, actually,

190
00:12:56,000 --> 00:13:03,000
what -- another thing I know is
that the -- I would like to be

191
00:13:03,000 --> 00:13:07,000
able to show is that the rows
are dependent.

192
00:13:07,000 --> 00:13:10,000
Maybe that's easier.

193
00:13:10,000 --> 00:13:15,000
If I know that all the columns
add to zero, that's my

194
00:13:15,000 --> 00:13:21,000
information, how do I see that
those three rows

195
00:13:21,000 --> 00:13:23,000
are linearly dependent?

196
00:13:23,000 --> 00:13:28,000
What -- what combination of
those rows gives the zero row?

197
00:13:28,000 --> 00:13:33,000
How -- how could I combine
those three rows -- those three

198
00:13:33,000 --> 00:13:36,000
row vectors to produce the zero
row vector?

199
00:13:36,000 --> 00:13:40,000
And that would tell me those
rows are dependent,

200
00:13:40,000 --> 00:13:44,000
therefore the columns are
dependent,

201
00:13:44,000 --> 00:13:47,000
the matrix is singular,
the determinant is zero --

202
00:13:47,000 --> 00:13:49,000
well, you see it.

203
00:13:49,000 --> 00:13:50,000
I just add the rows.

204
00:13:50,000 --> 00:13:54,000
One times that row plus one
times that row plus one times

205
00:13:54,000 --> 00:13:57,270
that row -- it's the zero row.

206
00:13:57,270 --> 00:13:59,000
The rows are dependent.

207
00:13:59,000 --> 00:14:03,000
In a way, that one one one,
because it's multiplying the

208
00:14:03,000 --> 00:14:07,000
rows,
is like an eigenvector in the

209
00:14:07,000 --> 00:14:11,000
-- it's in the left null space,
right?

210
00:14:11,000 --> 00:14:15,000
One one one is in the left null
space.

211
00:14:15,000 --> 00:14:22,000
It's singular because the rows
are dependent -- and can I just

212
00:14:22,000 --> 00:14:24,760
keep the reasoning going?

213
00:14:24,760 --> 00:14:29,000
Because this vector one one one
is --

214
00:14:29,000 --> 00:14:34,000
it's not in the null space of
the matrix, but it's in the null

215
00:14:34,000 --> 00:14:40,000
space of the transpose -- is in
the null space of the transpose.

216
00:14:40,000 --> 00:14:42,000
And that's good enough.

217
00:14:42,000 --> 00:14:47,560
If we have a square matrix --
if we have a square matrix and

218
00:14:47,560 --> 00:14:50,000
the rows are dependent,
that

219
00:14:50,000 --> 00:14:52,000
matrix is singular.

220
00:14:52,000 --> 00:14:57,000
So it turned out that the
immediate guy we could identify

221
00:14:57,000 --> 00:14:59,000
was one one one.

222
00:14:59,000 --> 00:15:05,000
Of course, the -- there will be
somebody in the null space,

223
00:15:05,000 --> 00:15:05,000
too.
And actually,
who will it be?

224
00:15:08,090 --> 00:15:13,000
So what's -- so -- so now I
want to ask about the

225
00:15:13,000 --> 00:15:16,000
null space of -- of the matrix
itself.

226
00:15:16,000 --> 00:15:19,000
What combination of the columns
gives zero?

227
00:15:19,000 --> 00:15:23,110
I -- I don't want to compute it
because I just made up this

228
00:15:23,110 --> 00:15:26,000
matrix and -- it will -- it
would take me a while -- it

229
00:15:26,000 --> 00:15:31,000
looks sort of doable
because it's three by three but

230
00:15:31,000 --> 00:15:34,000
wh- my point is,
what -- what vector is it if we

231
00:15:34,000 --> 00:15:39,000
-- once we've found it,
what have we got that's in the

232
00:15:39,000 --> 00:15:41,000
-- in the null space of A?

233
00:15:41,000 --> 00:15:43,000
It's the eigenvector,
right?

234
00:15:43,000 --> 00:15:46,000
That's where we find X one.

235
00:15:46,000 --> 00:15:51,000
Then X one, the eigenvector,
is in the null space of A.

236
00:15:51,000 --> 00:15:56,000
That's the eigenvector
corresponding to the eigenvalue

237
00:15:56,000 --> 00:15:56,000
one.
Right?

238
00:15:57,000 --> 00:16:00,000
That's how we find
eigenvectors.

239
00:16:00,000 --> 00:16:05,000
So those three columns must be
dependent -- some combination of

240
00:16:05,000 --> 00:16:10,290
columns --
of those three columns is the

241
00:16:10,290 --> 00:16:14,000
zero column and that -- the
three components in that

242
00:16:14,000 --> 00:16:17,000
combination are the eigenvector.

243
00:16:17,000 --> 00:16:19,000
And that guy is the steady
state.

244
00:16:19,000 --> 00:16:20,000
Okay.

245
00:16:20,000 --> 00:16:23,000
So I'm happy about the -- the
thinking here,

246
00:16:23,000 --> 00:16:28,000
but I haven't given -- I
haven't completed it because I

247
00:16:28,000 --> 00:16:29,000
haven't found x1.

248
00:16:29,000 --> 00:16:32,000
But it's there.

249
00:16:32,000 --> 00:16:39,000
Can I -- another thought came
to me as I was doing this,

250
00:16:39,000 --> 00:16:46,000
another little comment that --
you -- about eigenvalues and

251
00:16:46,000 --> 00:16:51,000
eigenvectors,
because of A and A transpose.

252
00:16:51,000 --> 00:16:58,000
What can you tell me about
eigenvalues of A -- of A and

253
00:16:58,000 --> 00:17:01,000
eigenvalues of A transpose?

254
00:17:01,000 --> 00:17:02,000
Whoops.

255
00:17:02,000 --> 00:17:06,000
They're the same.

256
00:17:06,000 --> 00:17:10,000
They're -- so this is a little
comment -- we -- it's useful,

257
00:17:10,000 --> 00:17:14,000
since eigenvalues are generally
not easy to find -- it's always

258
00:17:14,000 --> 00:17:17,000
useful to know some cases where
you've got them,

259
00:17:17,000 --> 00:17:21,000
where -- and this is -- if you
know the eigenvalues of A,

260
00:17:21,000 --> 00:17:25,000
then you know the eigenvalues
of A transpose.

261
00:17:25,000 --> 00:17:30,000
eigenvalues of A transpose are
the same.

262
00:17:30,000 --> 00:17:35,000
And can I just,
like, review why that is?

263
00:17:35,000 --> 00:17:42,000
So to find the eigenvalues of
A, this would be determinate of

264
00:17:42,000 --> 00:17:49,000
A minus lambda I equals zero,
that gives me an eigenvalue of

265
00:17:49,000 --> 00:17:57,000
A -- now how can I get A
transpose into the picture here?

266
00:17:57,000 --> 00:18:02,000
I'll use the fact that the
determinant of a matrix and the

267
00:18:02,000 --> 00:18:05,000
determinant of its transpose are
the same.

268
00:18:05,000 --> 00:18:09,000
The determinant of a matrix
equals the determinant of a --

269
00:18:09,000 --> 00:18:10,390
of the transpose.

270
00:18:10,390 --> 00:18:13,000
That was property ten,
the very last guy in our

271
00:18:13,000 --> 00:18:15,000
determinant list.

272
00:18:15,000 --> 00:18:18,000
So I'll transpose that matrix.

273
00:18:18,000 --> 00:18:24,430
This leads to -- I just take
the matrix and transpose it,

274
00:18:24,430 --> 00:18:29,000
but now what do I get when I
transpose lambda I?

275
00:18:29,000 --> 00:18:31,000
I just get lambda I.

276
00:18:31,000 --> 00:18:35,000
So that's -- that's all there
was to the

277
00:18:35,000 --> 00:18:36,000
reasoning.

278
00:18:36,000 --> 00:18:40,000
The reasoning is that the
eigenvalues of A solved that

279
00:18:40,000 --> 00:18:41,000
equation.

280
00:18:41,000 --> 00:18:44,000
The determinant of a matrix is
the determinant of its

281
00:18:44,000 --> 00:18:49,160
transpose, so that gives me this
equation and that tells me that

282
00:18:49,160 --> 00:18:53,000
the same lambdas are eigenvalues
of A transpose.

283
00:18:53,000 --> 00:18:56,000
So that, backing up to the
Markov case, one is an

284
00:18:56,000 --> 00:19:01,000
eigenvalue of A transpose and we
actually found its eigenvector,

285
00:19:01,000 --> 00:19:04,000
one one one,
and that tell us that one is

286
00:19:04,000 --> 00:19:08,000
also an eigenvalue of A -- but,
of course, it has a different

287
00:19:08,000 --> 00:19:11,660
eigenvector,
the -- the left null space

288
00:19:11,660 --> 00:19:15,000
isn't the same as the null space
and we would have to find it.

289
00:19:15,000 --> 00:19:19,000
So there's some vector here
which is x1 that produces zero

290
00:19:19,000 --> 00:19:19,000
zero zero.
Actually, it wouldn't be that
hard to find,

291
00:19:22,000 --> 00:19:25,000
you know, I -- as I'm talking
I'm thinking,

292
00:19:25,000 --> 00:19:29,000
okay, I going to follow through
and actually find it?

293
00:19:29,000 --> 00:19:34,000
Well, I can tell from this one
-- look, if I put a point six

294
00:19:34,000 --> 00:19:39,000
there and a point seven there,
that's what -- then I'll be

295
00:19:39,000 --> 00:19:41,000
okay in the last row,
right?

296
00:19:41,000 --> 00:19:45,000
Now I only -- remains to find
one guy.

297
00:19:45,000 --> 00:19:48,000
And let me take the first row,
then.

298
00:19:48,000 --> 00:19:54,000
Minus point 54 plus point 21 --
there's some big number going in

299
00:19:54,000 --> 00:19:55,540
there, right?

300
00:19:55,540 --> 00:19:59,000
So I have -- just to make the
first row come out zero,

301
00:19:59,000 --> 00:20:04,000
I'm getting minus point 54 plus
point 21, so that was minus

302
00:20:04,000 --> 00:20:07,000
point 33 and what -- what do I
want?

303
00:20:07,000 --> 00:20:09,000
Like thirty three hundred?

304
00:20:09,000 --> 00:20:13,000
This is the first time in the
history of linear algebra that

305
00:20:13,000 --> 00:20:17,000
an
eigenvector has every had a

306
00:20:17,000 --> 00:20:19,000
component thirty three hundred.

307
00:20:19,000 --> 00:20:21,000
But I guess it's true.

308
00:20:21,000 --> 00:20:26,000
Because then I multiply by
minus one over a hundred -- oh

309
00:20:26,000 --> 00:20:27,000
no, it was point 33.

310
00:20:27,000 --> 00:20:30,000
So is this just -- oh,
shoot.

311
00:20:30,000 --> 00:20:30,000
Only 33.
Okay.

312
00:20:31,000 --> 00:20:31,000
Only 33.
Okay, so there's the
eigenvector.

313
00:20:35,000 --> 00:20:39,740
Oh, and notice that it -- that
it turned -- did turn out,

314
00:20:39,740 --> 00:20:41,000
at least, to be all positive.

315
00:20:41,000 --> 00:20:45,000
So that was,
like, the theory -- predicts

316
00:20:45,000 --> 00:20:46,000
that part, too.

317
00:20:46,000 --> 00:20:48,000
I won't give the proof of that
part.

318
00:20:48,000 --> 00:20:51,000
So 30 -- 33 -- point six 33
point seven.

319
00:20:51,000 --> 00:20:52,000
Okay.

320
00:20:52,000 --> 00:20:57,000
Now those are the ma- that's
the linear algebra part.

321
00:20:57,000 --> 00:20:59,000
Can I get to the applications?

322
00:20:59,000 --> 00:21:01,000
Where do these Markov matrices
come from?

323
00:21:01,000 --> 00:21:05,000
Because that's -- that's part
of this course and absolutely

324
00:21:05,000 --> 00:21:07,000
part of this lecture.

325
00:21:07,000 --> 00:21:07,000
Okay.
So where's -- what's an
application of Markov matrices?

326
00:21:12,000 --> 00:21:12,000
Okay.
Markov matrices -- so,
my equation,

327
00:21:17,000 --> 00:21:24,000
then, that I'm solving and
studying is this equation

328
00:21:24,000 --> 00:21:25,000
u(k+1)=Auk.

329
00:21:25,000 --> 00:21:29,570
And now A is a Markov matrix.

330
00:21:29,570 --> 00:21:31,000
A is Markov.

331
00:21:31,000 --> 00:21:35,000
And I want to give an example.

332
00:21:35,000 --> 00:21:39,000
Can I just create an example?

333
00:21:39,000 --> 00:21:43,000
It'll be two by two.

334
00:21:43,000 --> 00:21:48,000
And it's one I've used before
because it seems to me to bring

335
00:21:48,000 --> 00:21:50,000
out the idea.

336
00:21:50,000 --> 00:21:55,000
It's -- because we have two by
two, we have two states,

337
00:21:55,000 --> 00:21:58,000
let's say California and
Massachusetts.

338
00:21:58,000 --> 00:22:03,000
And I'm looking at the
populations in those two states,

339
00:22:03,000 --> 00:22:10,000
the people in those two states,
California and Massachusetts.

340
00:22:10,000 --> 00:22:14,000
And my matrix A is going to
tell me in a -- in a year,

341
00:22:14,000 --> 00:22:16,000
some movement has happened.

342
00:22:16,000 --> 00:22:18,000
Some people stayed in
Massachusetts,

343
00:22:18,000 --> 00:22:22,000
some people moved to
California, some smart people

344
00:22:22,000 --> 00:22:24,000
moved from California to
Massachusetts,

345
00:22:24,000 --> 00:22:29,000
some people stayed in
California and made a billion.

346
00:22:29,000 --> 00:22:29,000
Okay.
So that -- there's a matrix
there with four entries and

347
00:22:33,000 --> 00:22:38,000
those tell me the fractions of
my population -- so I'm making

348
00:22:38,000 --> 00:22:42,000
-- I'm going to use fractions,
so they won't be negative,

349
00:22:42,000 --> 00:22:47,000
of course, because -- because
only positive people are in-

350
00:22:47,000 --> 00:22:51,000
involved here -- and they'll
add up to one,

351
00:22:51,000 --> 00:22:53,000
because I'm accounting for all
people.

352
00:22:53,000 --> 00:22:57,000
So that's why I have these two
key properties.

353
00:22:57,000 --> 00:23:01,000
The entries are greater equal
zero because I'm looking at

354
00:23:01,000 --> 00:23:02,000
probabilities.

355
00:23:02,000 --> 00:23:05,000
Do they move,
do they stay?

356
00:23:05,000 --> 00:23:09,000
Those probabilities are all
between zero and one.

357
00:23:09,000 --> 00:23:12,000
And the probabilities add to
one because everybody's

358
00:23:12,000 --> 00:23:13,000
accounted for.

359
00:23:13,000 --> 00:23:17,000
I'm not losing anybody,
gaining anybody in this Markov

360
00:23:17,000 --> 00:23:18,000
chain.

361
00:23:18,000 --> 00:23:21,000
It's -- it conserves the total
population.

362
00:23:21,000 --> 00:23:21,000
Okay.
So what would be a typical
matrix, then?

363
00:23:25,000 --> 00:23:31,000
So this would be u,
California and u Massachusetts

364
00:23:31,000 --> 00:23:34,000
at time t equal k+1.

365
00:23:34,000 --> 00:23:39,000
And it's some matrix,
which we'll think of,

366
00:23:39,000 --> 00:23:45,830
times u California and u
Massachusetts at time k.

367
00:23:45,830 --> 00:23:51,000
And notice this matrix is going
to stay the same,

368
00:23:51,000 --> 00:23:54,000
you know, forever.

369
00:23:54,000 --> 00:24:00,000
So that's a severe limitation
on the example.

370
00:24:00,000 --> 00:24:05,000
The example has a -- the same
Markov matrix,

371
00:24:05,000 --> 00:24:09,000
the same probabilities act at
every time.

372
00:24:09,000 --> 00:24:09,000
Okay.
So what's a reasonable,
say -- say point nine of the

373
00:24:14,780 --> 00:24:18,000
people in California at time k
stay there.

374
00:24:18,000 --> 00:24:23,000
And point one of the people in
California move to

375
00:24:23,000 --> 00:24:26,000
Massachusetts.

376
00:24:26,000 --> 00:24:31,000
Notice why that column added to
one, because we've now accounted

377
00:24:31,000 --> 00:24:34,310
for all the people in California
at time k.

378
00:24:34,310 --> 00:24:37,000
Nine tenths of them are still
in California,

379
00:24:37,000 --> 00:24:39,000
one tenth are here at time k+1.

380
00:24:39,000 --> 00:24:40,000
Okay.

381
00:24:40,000 --> 00:24:43,000
What about the people who are
in Massachusetts?

382
00:24:43,000 --> 00:24:46,000
This is going to multiply
column two, right,

383
00:24:46,000 --> 00:24:51,000
by our
fundamental rule of multiplying

384
00:24:51,000 --> 00:24:56,000
matrix by vector,
it's the -- it's the population

385
00:24:56,000 --> 00:24:58,000
in Massachusetts.

386
00:24:58,000 --> 00:25:04,250
Shall we say that -- that after
the Red Sox, fail again,

387
00:25:04,250 --> 00:25:10,000
eight -- only 80 percent of the
people in Massachusetts stay and

388
00:25:10,000 --> 00:25:14,000
20 percent
move to California.

389
00:25:14,000 --> 00:25:14,000
Okay.
So again, this adds to one,
which accounts for all people

390
00:25:19,000 --> 00:25:21,000
in Massachusetts where they are.

391
00:25:21,000 --> 00:25:23,000
So there is a Markov matrix.

392
00:25:23,000 --> 00:25:26,000
Non-negative entries adding to
one.

393
00:25:26,000 --> 00:25:28,000
What's the steady state?

394
00:25:28,000 --> 00:25:32,000
If everybody started in
Massachusetts,

395
00:25:32,000 --> 00:25:36,000
say, at -- you know,
when the Pilgrims showed up or

396
00:25:36,000 --> 00:25:36,000
something.
Then where are they now?

397
00:25:38,000 --> 00:25:43,000
Where are they at time 100,
let's say, or maybe -- I don't

398
00:25:43,000 --> 00:25:46,000
know, how many years since the
Pilgrims?

399
00:25:46,000 --> 00:25:47,000
300 and something.

400
00:25:47,000 --> 00:25:51,000
Or -- and actually where will
they be, like,

401
00:25:51,000 --> 00:25:54,000
way out a million
years from now?

402
00:25:54,000 --> 00:25:59,000
I -- I could multiply -- take
the powers of this matrix.

403
00:25:59,000 --> 00:26:05,000
In fact, you'll -- you would --
ought to be able to figure out

404
00:26:05,000 --> 00:26:09,000
what is the hundredth power of
that matrix?

405
00:26:09,000 --> 00:26:11,000
Why don't we do that?

406
00:26:11,000 --> 00:26:15,000
But let me follow the steady
state.

407
00:26:15,000 --> 00:26:20,000
So what -- what's my starting
-- my starting u Cal,

408
00:26:20,000 --> 00:26:26,000
u Mass at time zero is,
shall we say -- shall we put

409
00:26:26,000 --> 00:26:28,800
anybody in California?

410
00:26:28,800 --> 00:26:35,000
Let's make -- let's make zero
there, and say the population of

411
00:26:35,000 --> 00:26:41,000
Massachusetts is --
let's say a thousand just to --

412
00:26:41,000 --> 00:26:42,000
okay.

413
00:26:42,000 --> 00:26:47,680
So the population is -- so the
populations are zero and a

414
00:26:47,680 --> 00:26:49,000
thousand at the start.

415
00:26:49,000 --> 00:26:55,000
What can you tell me about this
population after -- after k

416
00:26:55,000 --> 00:26:56,000
steps?

417
00:26:56,000 --> 00:26:59,000
What will u Cal plus u Mass add
to?

418
00:26:59,000 --> 00:27:00,700
A thousand.

419
00:27:00,700 --> 00:27:06,000
Those thousand people are
always accounted for.

420
00:27:06,000 --> 00:27:10,000
But -- so u Mass will start
dropping from a thousand and u

421
00:27:10,000 --> 00:27:12,000
Cal will start growing.

422
00:27:12,000 --> 00:27:17,000
Actually, we could see -- why
don't we figure out what it is

423
00:27:17,000 --> 00:27:18,000
after one?

424
00:27:18,000 --> 00:27:22,000
After one time step,
what are the populations at

425
00:27:22,000 --> 00:27:23,000
time one?

426
00:27:23,000 --> 00:27:26,000
So what happens in one step?

427
00:27:26,000 --> 00:27:30,000
You multiply once by that
matrix and, let's see,

428
00:27:30,000 --> 00:27:35,000
zero times this column -- so
it's just a thousand times this

429
00:27:35,000 --> 00:27:38,000
column, so I think we're getting
200 and 800.

430
00:27:38,000 --> 00:27:42,000
So after the first step,
200 people have -- are in

431
00:27:42,000 --> 00:27:43,000
California.

432
00:27:43,000 --> 00:27:48,000
Now at the following step,
I'll multiply again by this

433
00:27:48,000 --> 00:27:52,000
matrix -- more people will move
to California.

434
00:27:52,000 --> 00:27:54,640
Some people will move back.

435
00:27:54,640 --> 00:27:59,000
Twenty people will come back
and, the -- the net result will

436
00:27:59,000 --> 00:28:03,000
be that the California
population will be above 200 and

437
00:28:03,000 --> 00:28:08,000
the Massachusetts below 800 and
they'll still add up to a

438
00:28:08,000 --> 00:28:09,000
thousand.

439
00:28:09,000 --> 00:28:10,300
Okay.

440
00:28:10,300 --> 00:28:11,000
I do that a few times.

441
00:28:11,000 --> 00:28:13,000
I do that 100 times.

442
00:28:13,000 --> 00:28:15,000
What's the population?

443
00:28:15,000 --> 00:28:18,000
Well, okay, to answer any
question like that,

444
00:28:18,000 --> 00:28:21,000
I need the eigenvalues and
eigenvectors,

445
00:28:21,000 --> 00:28:21,000
right?
As soon as I've -- I've created
an example, but as soon as I

446
00:28:26,000 --> 00:28:31,000
want to solve anything,
I have to find eigenvalues and

447
00:28:31,000 --> 00:28:34,000
eigenvectors of that matrix.

448
00:28:34,000 --> 00:28:34,850
Okay.

449
00:28:34,850 --> 00:28:36,000
So let's do it.

450
00:28:36,000 --> 00:28:41,090
So there's the matrix .9,
.2, .1, .8 and tell me its

451
00:28:41,090 --> 00:28:42,000
eigenvalues.

452
00:28:42,000 --> 00:28:46,000
Lambda equals -- so tell me one
eigenvalue?

453
00:28:46,000 --> 00:28:48,000
One, thanks.

454
00:28:48,000 --> 00:28:50,660
And tell me the other one.

455
00:28:50,660 --> 00:28:55,150
What's the other eigenvalue --
from the trace or the

456
00:28:55,150 --> 00:28:59,000
determinant -- from the -- I --
the trace is what -- is,

457
00:28:59,000 --> 00:29:01,000
like, easier.

458
00:29:01,000 --> 00:29:05,000
So the trace of that matrix is
one point seven.

459
00:29:05,000 --> 00:29:08,000
So the other eigenvalue is
point seven.

460
00:29:08,000 --> 00:29:12,000
And it -- notice that
it's less than one.

461
00:29:12,000 --> 00:29:16,000
And notice that that
determinant is point 72-.02,

462
00:29:16,000 --> 00:29:18,000
which is point seven.

463
00:29:18,000 --> 00:29:18,000
Right.
Okay.

464
00:29:19,210 --> 00:29:21,000
Now to find the eigenvectors.

465
00:29:21,000 --> 00:29:26,000
This is -- so that's lambda one
and the eigenvector -- I'll

466
00:29:26,000 --> 00:29:29,000
subtract one from the diagonal,
right?

467
00:29:29,000 --> 00:29:33,000
So can I do that in light let
-- in light here?

468
00:29:33,000 --> 00:29:38,000
Subtract one from the diagonal,
I have minus point one and

469
00:29:38,000 --> 00:29:42,000
minus point two,
and of course these are still

470
00:29:42,000 --> 00:29:42,000
there.
And I'm looking for its --
here's -- here's -- this is

471
00:29:47,000 --> 00:29:48,000
going to be x1.

472
00:29:48,000 --> 00:29:51,000
It's the null space of A minus
I.

473
00:29:51,000 --> 00:29:55,000
Okay, everybody sees that it's
two and one.

474
00:29:55,000 --> 00:29:56,000
Okay?

475
00:29:56,000 --> 00:30:01,000
And now how about -- so that --
and it -- notice that that

476
00:30:01,000 --> 00:30:03,000
eigenvector is positive.

477
00:30:03,000 --> 00:30:07,000
And actually,
we can jump to infinity right

478
00:30:07,000 --> 00:30:08,000
now.

479
00:30:08,000 --> 00:30:11,000
What's the population at
infinity?

480
00:30:11,000 --> 00:30:16,800
It's a multiple -- this is --
this eigenvector is

481
00:30:16,800 --> 00:30:18,000
giving the steady state.

482
00:30:18,000 --> 00:30:22,000
It's some multiple of this,
and how is that multiple

483
00:30:22,000 --> 00:30:23,000
decided?

484
00:30:23,000 --> 00:30:26,000
By adding up to a thousand
people.

485
00:30:26,000 --> 00:30:29,000
So the steady state,
the c1x1 -- this is the x1,

486
00:30:29,000 --> 00:30:34,000
but that adds up to three,
so I really want two -- it's

487
00:30:34,000 --> 00:30:38,000
going to be two thirds of a
thousand and one third of a

488
00:30:38,000 --> 00:30:42,000
thousand,
making a total of the thousand

489
00:30:42,000 --> 00:30:42,000
people.
That'll be the steady state.

490
00:30:44,000 --> 00:30:47,730
That's really all I need to
know at infinity.

491
00:30:47,730 --> 00:30:51,000
But if I want to know what's
happened after just a finite

492
00:30:51,000 --> 00:30:54,000
number like 100 steps,
I'd better find this

493
00:30:54,000 --> 00:30:55,000
eigenvector.

494
00:30:55,000 --> 00:30:59,000
So can I --
can I look at -- I'll subtract

495
00:30:59,000 --> 00:31:04,000
point seven time -- ti- from the
diagonal and I'll get that and

496
00:31:04,000 --> 00:31:08,000
I'll look at the null space of
that one and I -- and this is

497
00:31:08,000 --> 00:31:11,000
going to give me x2,
now, and what is it?

498
00:31:11,000 --> 00:31:16,000
So what's in the null space of
-- that's certainly singular,

499
00:31:16,000 --> 00:31:20,000
so I know my calculation is
right,

500
00:31:20,000 --> 00:31:22,000
and -- one and minus one.

501
00:31:22,000 --> 00:31:23,000
One and minus one.

502
00:31:23,000 --> 00:31:28,000
So I'm prepared now to write
down the solution after 100 time

503
00:31:28,000 --> 00:31:28,000
steps.
The -- the populations after
100 time steps,

504
00:31:32,000 --> 00:31:32,000
right?
Can -- can we remember the
point one -- the -- the one with

505
00:31:37,000 --> 00:31:43,000
this two one eigenvector and the
point seven with the minus

506
00:31:43,000 --> 00:31:45,000
one one eigenvector.

507
00:31:45,000 --> 00:31:50,000
So I'll -- let me -- I'll just
write it above here.

508
00:31:50,000 --> 00:31:56,000
u after k steps is some
multiple of one to the k times

509
00:31:56,000 --> 00:32:03,000
the two one eigenvector and some
multiple of point seven to the k

510
00:32:03,000 --> 00:32:06,000
times the minus one one
eigenvector.

511
00:32:06,000 --> 00:32:07,000
Right?

512
00:32:07,000 --> 00:32:12,000
That's --
I -- this is how I take -- how

513
00:32:12,000 --> 00:32:15,000
powers of a matrix work.

514
00:32:15,000 --> 00:32:21,820
When I apply those powers to a
u0, what I -- so it's u0,

515
00:32:21,820 --> 00:32:28,000
which was zero a thousand --
that has to be corrected k=0.

516
00:32:28,000 --> 00:32:34,000
So I'm plugging in k=0 and I
get c1 times two one and c2

517
00:32:34,000 --> 00:32:37,000
times minus one one.

518
00:32:37,000 --> 00:32:40,000
Two equations,
two constants,

519
00:32:40,000 --> 00:32:43,000
certainly independent
eigenvectors,

520
00:32:43,000 --> 00:32:48,000
so there's a solution and you
see what it is?

521
00:32:48,000 --> 00:32:54,000
Let's see, I guess we already
figured that c1 was a thousand

522
00:32:54,000 --> 00:32:59,000
over three, I think -- did we
think that had to

523
00:32:59,000 --> 00:33:01,000
be a thousand over three?

524
00:33:01,000 --> 00:33:07,000
And maybe c2 would be -- excuse
me, let -- get an eraser -- we

525
00:33:07,000 --> 00:33:11,000
can -- I just -- I think we've
-- get it here.

526
00:33:11,000 --> 00:33:16,000
c2, we want to get a zero here,
so maybe we need plus two

527
00:33:16,000 --> 00:33:18,000
thousand over three.

528
00:33:18,000 --> 00:33:21,030
I think that has to work.

529
00:33:21,030 --> 00:33:26,000
Two times a thousand over three
minus two thousand over three,

530
00:33:26,000 --> 00:33:31,000
that'll give us the zero and a
thousand over three and the two

531
00:33:31,000 --> 00:33:35,000
thousand over three will give us
three thousand over three,

532
00:33:35,000 --> 00:33:35,000
the thousand.
So this is what we approach --
this part, with the point seven

533
00:33:40,000 --> 00:33:44,180
to the k-th power is the part
that's disappearing.

534
00:33:44,180 --> 00:33:44,000
Okay.

535
00:33:44,000 --> 00:33:48,000
That's -- that's Markov
matrices.

536
00:33:48,000 --> 00:33:53,000
That's an example of where they
come from, from modeling

537
00:33:53,000 --> 00:33:59,000
movement of people with no gain
or loss, with total -- total

538
00:33:59,000 --> 00:34:01,000
count conserved.

539
00:34:01,000 --> 00:34:02,000
Okay.

540
00:34:02,000 --> 00:34:07,000
I -- just if I can add one more
comment,

541
00:34:07,000 --> 00:34:11,000
because you'll see Markov
matrices in electrical

542
00:34:11,000 --> 00:34:15,940
engineering courses and often
you'll see them -- sorry,

543
00:34:15,940 --> 00:34:18,000
here's my little comment.

544
00:34:18,000 --> 00:34:22,000
Sometimes -- in a lot of
applications they prefer to work

545
00:34:22,000 --> 00:34:24,000
with row vectors.

546
00:34:24,000 --> 00:34:28,000
So they -- instead of -- this
was natural for us,

547
00:34:28,000 --> 00:34:29,000
right?

548
00:34:29,000 --> 00:34:33,000
For all the eigenvectors to be
column vectors.

549
00:34:33,000 --> 00:34:37,000
So our columns added to one in
the Markov matrix.

550
00:34:37,000 --> 00:34:41,000
Just so you don't think,
well, what -- what's going on?

551
00:34:41,000 --> 00:34:47,000
If we work with row vectors and
we multiply vector times matrix

552
00:34:47,000 --> 00:34:52,000
-- so we're multiplying from
the left -- then it'll be the

553
00:34:52,000 --> 00:34:57,000
then we'll be using the
transpose of -- of this matrix

554
00:34:57,000 --> 00:35:00,000
and it'll be the rows that add
to one.

555
00:35:00,000 --> 00:35:04,000
So in other textbooks,
you'll see -- instead of col-

556
00:35:04,000 --> 00:35:08,000
columns adding to one,
you'll see rows add to one.

557
00:35:08,000 --> 00:35:08,000
Okay.
Fine.

558
00:35:10,000 --> 00:35:14,000
Okay, that's what I wanted to
say about Markov,

559
00:35:14,000 --> 00:35:18,000
now I want to say something
about projections and even

560
00:35:18,000 --> 00:35:22,000
leading in -- a little into
Fourier series.

561
00:35:22,000 --> 00:35:25,000
Because -- but before any
Fourier stuff,

562
00:35:25,000 --> 00:35:29,370
let me make a comment about
projections.

563
00:35:29,370 --> 00:35:35,000
This -- so this is a comment
about projections onto --

564
00:35:35,000 --> 00:35:38,000
with an orthonormal basis.

565
00:35:38,000 --> 00:35:44,000
So, of course,
the basis vectors are q1 up to

566
00:35:44,000 --> 00:35:44,000
qn.
Okay.

567
00:35:45,000 --> 00:35:48,110
I have a vector b.

568
00:35:48,110 --> 00:35:55,000
Let -- let me imagine -- let me
imagine this is a basis.

569
00:35:55,000 --> 00:35:59,780
Let -- let's say I'm in n by n.

570
00:35:59,780 --> 00:36:03,000
I'm -- I've got,
eh,

571
00:36:03,000 --> 00:36:08,000
n orthonormal vectors,
I'm in n dimensional space so

572
00:36:08,000 --> 00:36:15,140
they're a complete -- they're a
basis -- any vector v could be

573
00:36:15,140 --> 00:36:17,000
expanded in this basis.

574
00:36:17,000 --> 00:36:22,000
So any vector v is some
combination, some amount of q1

575
00:36:22,000 --> 00:36:28,000
plus some amount of q2 plus some
amount of qn.

576
00:36:28,000 --> 00:36:30,000
So -- so any v.

577
00:36:30,000 --> 00:36:35,000
I just want you to tell me what
those amounts are.

578
00:36:35,000 --> 00:36:40,000
What are x1 -- what's x1,
for example?

579
00:36:40,000 --> 00:36:43,000
So I'm looking for the
expansion.

580
00:36:43,000 --> 00:36:48,000
This is -- this is really our
projection.

581
00:36:48,000 --> 00:36:55,000
I could -- I could really use
the word expansion.

582
00:36:55,000 --> 00:36:59,000
I'm expanding the vector in the
basis.

583
00:36:59,000 --> 00:37:05,000
And the special thing about the
basis is that it's orthonormal.

584
00:37:05,000 --> 00:37:10,000
So that should give me a
special formula for the answer,

585
00:37:10,000 --> 00:37:12,000
for the coefficients.

586
00:37:12,000 --> 00:37:14,000
So how do I get x1?

587
00:37:14,000 --> 00:37:17,000
What -- what's a formula for
x1?

588
00:37:17,000 --> 00:37:23,000
I could -- I can go through the
projection -- the Q transpose

589
00:37:23,000 --> 00:37:28,000
Q, all that -- normal equations,
but -- and I'll get -- I'll

590
00:37:28,000 --> 00:37:33,000
come out with this nice answer
that I think I can see right

591
00:37:33,000 --> 00:37:34,000
away.

592
00:37:34,000 --> 00:37:39,000
How can I pick -- get a hold of
x1 and get these other x-s out

593
00:37:39,000 --> 00:37:41,000
of the equation?

594
00:37:41,000 --> 00:37:44,000
So how can I get a nice,
simple

595
00:37:44,000 --> 00:37:46,000
formula for x1?

596
00:37:46,000 --> 00:37:50,000
And then we want to see,
sure, we knew that all the

597
00:37:50,000 --> 00:37:51,000
time.

598
00:37:51,000 --> 00:37:51,000
Okay.
So what's x1?

599
00:37:52,000 --> 00:37:58,010
The good way is take the inner
product of everything with q1.

600
00:37:58,010 --> 00:38:02,000
Take the inner product of that
whole equation,

601
00:38:02,000 --> 00:38:03,000
every term, with q1.

602
00:38:03,000 --> 00:38:06,000
What will happen to that last
term?

603
00:38:06,000 --> 00:38:12,200
The inner product --
when -- if I take the dot

604
00:38:12,200 --> 00:38:15,000
product with q1 I get zero,
right?

605
00:38:15,000 --> 00:38:18,000
Because this basis was
orthonormal.

606
00:38:18,000 --> 00:38:22,000
If I take the dot product with
q2 I get zero.

607
00:38:22,000 --> 00:38:26,000
If I take the dot product with
q1 I get one.

608
00:38:26,000 --> 00:38:30,000
So that tells me what x1 is.
q1 transpose v,

609
00:38:30,000 --> 00:38:36,000
that's taking the dot product,
is x1 times q1 transpose q1

610
00:38:36,000 --> 00:38:38,000
plus a bunch of zeroes.

611
00:38:38,000 --> 00:38:42,000
And this is a one,
so I can forget that.

612
00:38:42,000 --> 00:38:44,000
I get x1 immediately.

613
00:38:44,000 --> 00:38:49,000
So -- do you see what I'm
saying -- is that I have an

614
00:38:49,000 --> 00:38:54,050
orthonormal basis,
then the coefficient that I

615
00:38:54,050 --> 00:38:58,000
need for
each basis vector is a cinch to

616
00:38:58,000 --> 00:38:58,000
find.
Let me -- let me just -- I have
to put this into matrix

617
00:39:02,000 --> 00:39:06,000
language, too,
so you'll see it there also.

618
00:39:06,000 --> 00:39:10,000
If I write that first equation
in matrix language,

619
00:39:10,000 --> 00:39:11,000
what -- what is it?

620
00:39:11,000 --> 00:39:15,000
I'm writing --
in matrix language,

621
00:39:15,000 --> 00:39:21,000
this equation says I'm taking
these columns -- are -- are you

622
00:39:21,000 --> 00:39:23,000
guys good at this now?

623
00:39:23,000 --> 00:39:29,000
I'm taking those columns times
the Xs and getting V,

624
00:39:29,000 --> 00:39:29,830
right?

625
00:39:29,830 --> 00:39:32,000
That's the matrix form.

626
00:39:32,000 --> 00:39:34,000
Okay, that's the matrix Q.

627
00:39:34,000 --> 00:39:35,000
Qx is v.

628
00:39:35,000 --> 00:39:40,380
What's the solution
to that equation?

629
00:39:40,380 --> 00:39:44,000
It's -- of course,
it's x equal Q inverse v.

630
00:39:44,000 --> 00:39:48,000
So x is Q inverse v,
but what's the point?

631
00:39:48,000 --> 00:39:53,000
Q inverse in this case is going
to -- is simple.

632
00:39:53,000 --> 00:39:57,000
I don't have to work to invert
this matrix Q,

633
00:39:57,000 --> 00:40:03,000
because of the fact that the --
these columns are orthonormal,

634
00:40:03,000 --> 00:40:06,390
I know the inverse to that.

635
00:40:06,390 --> 00:40:08,000
And it is Q transpose.

636
00:40:08,000 --> 00:40:12,000
When you see a Q,
a square matrix with that

637
00:40:12,000 --> 00:40:16,000
letter Q, the -- that just
triggers -- Q inverse is the

638
00:40:16,000 --> 00:40:18,000
same as Q transpose.

639
00:40:18,000 --> 00:40:23,000
So the first component,
then -- the first component of

640
00:40:23,000 --> 00:40:29,000
x is the first row times
v, and what's that?

641
00:40:29,000 --> 00:40:35,000
The first component of this
answer is the first row of Q

642
00:40:35,000 --> 00:40:37,230
transpose.

643
00:40:37,230 --> 00:40:43,000
That's just -- that's just q1
transpose times v.

644
00:40:43,000 --> 00:40:47,000
So that's what we concluded
here, too.

645
00:40:47,000 --> 00:40:48,000
Okay.

646
00:40:48,000 --> 00:40:52,000
So -- so nothing Fourier here.

647
00:40:52,000 --> 00:40:57,000
The -- the key ingredient here
was

648
00:40:57,000 --> 00:41:01,230
that the q-s are orthonormal.

649
00:41:01,230 --> 00:41:06,000
And now that's what Fourier
series are built on.

650
00:41:06,000 --> 00:41:12,000
So now, in the remaining time,
let me say something about

651
00:41:12,000 --> 00:41:14,000
Fourier series.

652
00:41:14,000 --> 00:41:15,000
Okay.

653
00:41:15,000 --> 00:41:21,000
So Fourier series is -- well,
we've got a function f of x.

654
00:41:21,000 --> 00:41:28,000
And we want to write it as a
combination of -- maybe

655
00:41:28,000 --> 00:41:31,000
it has a constant term.

656
00:41:31,000 --> 00:41:34,000
And then it has some cos(x) in
it.

657
00:41:34,000 --> 00:41:38,000
And it has some sin(x) in it.

658
00:41:38,000 --> 00:41:41,000
And it has some cos(2x) in it.

659
00:41:41,000 --> 00:41:46,000
And a -- and some sin(2x),
and forever.

660
00:41:46,000 --> 00:41:51,000
So what's -- what's the
difference between this type

661
00:41:51,000 --> 00:41:55,260
problem and the one above it?

662
00:41:55,260 --> 00:42:02,000
This one's infinite,
but the key property of things

663
00:42:02,000 --> 00:42:07,830
being orthogonal is still true
for sines and cosines,

664
00:42:07,830 --> 00:42:13,430
so it's the property that makes
Fourier series work.

665
00:42:13,430 --> 00:42:17,000
So that's called a Fourier
series.

666
00:42:17,000 --> 00:42:19,000
Better write his name up.

667
00:42:19,000 --> 00:42:22,000
Fourier series.

668
00:42:22,000 --> 00:42:26,000
So it was Joseph Fourier who
realized that,

669
00:42:26,000 --> 00:42:28,000
hey, I could work in function
space.

670
00:42:28,000 --> 00:42:33,000
Instead of a vector v,
I could have a function f of x.

671
00:42:33,000 --> 00:42:37,000
Instead of orthogonal vectors,
q1, q2 , q3,

672
00:42:37,000 --> 00:42:41,000
I could have orthogonal
functions, the constant,

673
00:42:41,000 --> 00:42:45,000
the cos(x), the sin(x),
the s- cos(2x),

674
00:42:45,000 --> 00:42:47,000
but infinitely many of them.

675
00:42:47,000 --> 00:42:51,000
I need infinitely many,
because my space is infinite

676
00:42:51,000 --> 00:42:52,000
dimensional.

677
00:42:52,000 --> 00:42:55,390
So this is, like,
the moment in which we leave

678
00:42:55,390 --> 00:42:59,000
finite dimensional vector spaces
and go to infinite dimensional

679
00:42:59,000 --> 00:43:04,000
vector spaces and our basis --
so the vectors are now

680
00:43:04,000 --> 00:43:09,000
functions -- and of course,
there are so many functions

681
00:43:09,000 --> 00:43:13,000
that it's -- that we've got an
infin- infinite dimensional

682
00:43:13,000 --> 00:43:17,000
space -- and the basis vectors
are functions,

683
00:43:17,000 --> 00:43:19,790
too.
a0, the constant function one

684
00:43:19,790 --> 00:43:24,000
-- so my basis is one cos(x),
sin(x), cos(2x),

685
00:43:24,000 --> 00:43:26,000
sin(2x) and so on.

686
00:43:26,000 --> 00:43:32,000
And the reason Fourier series
is a success is that those are

687
00:43:32,000 --> 00:43:33,000
orthogonal.

688
00:43:33,000 --> 00:43:33,000
Okay.
Now what do I mean by
orthogonal?

689
00:43:37,000 --> 00:43:42,000
I know what it means for two
vectors to be orthogonal -- y

690
00:43:42,000 --> 00:43:46,000
transpose x equals zero,
right?

691
00:43:46,000 --> 00:43:48,000
Dot product equals zero.

692
00:43:48,000 --> 00:43:51,720
But what's the dot product of
functions?

693
00:43:51,720 --> 00:43:56,000
I'm claiming that whatever it
is, the dot product -- or we

694
00:43:56,000 --> 00:43:59,000
would more likely use the word
inner product of,

695
00:43:59,000 --> 00:44:02,000
say, cos(x) with sin(x) is
zero.

696
00:44:02,000 --> 00:44:04,000
And cos(x) with cos(2x),
also zero.

697
00:44:04,000 --> 00:44:08,000
So I -- let me tell you what I
mean

698
00:44:08,000 --> 00:44:12,000
by that, by that dot product.

699
00:44:12,000 --> 00:44:17,000
Well, how do I compute a dot
product?

700
00:44:17,000 --> 00:44:24,000
So, let's just remember for
vectors v trans- v transpose w

701
00:44:24,000 --> 00:44:32,000
for vectors, so this was
vectors, v transpose w was v1w1

702
00:44:32,000 --> 00:44:33,590
+...+vnwn.

703
00:44:33,590 --> 00:44:34,000
Okay.

704
00:44:34,000 --> 00:44:36,000
Now functions.

705
00:44:36,000 --> 00:44:42,000
Now I have two functions,
let's call them f and g.

706
00:44:42,000 --> 00:44:44,000
What's with them now?

707
00:44:44,000 --> 00:44:49,000
The vectors had n components,
but the functions have a whole,

708
00:44:49,000 --> 00:44:50,000
like, continuum.

709
00:44:50,000 --> 00:44:54,000
To graph the function,
I just don't have n points,

710
00:44:54,000 --> 00:44:56,000
I've got this whole graph.

711
00:44:56,000 --> 00:45:01,000
So I have functions -- I'm
really trying to ask you what's

712
00:45:01,000 --> 00:45:07,000
the inner product of this
function f with another function

713
00:45:07,000 --> 00:45:07,000
g?
And I want to make it parallel
to this the best I can.

714
00:45:13,000 --> 00:45:18,000
So the best parallel is to
multiply f (x) times g(x) at

715
00:45:18,000 --> 00:45:23,230
every x -- and here I just had n
multiplications,

716
00:45:23,230 --> 00:45:27,000
but here I'm going to have a
whole range of x-s,

717
00:45:27,000 --> 00:45:31,000
and here
I added the results.

718
00:45:31,000 --> 00:45:33,480
What do I do here?

719
00:45:33,480 --> 00:45:38,000
So what's the analog of
addition when you have -- when

720
00:45:38,000 --> 00:45:40,000
you're in a continuum?

721
00:45:40,000 --> 00:45:42,000
It's integration.

722
00:45:42,000 --> 00:45:47,000
So that the -- the dot product
of two functions will be the

723
00:45:47,000 --> 00:45:51,000
integral of those functions,
dx.

724
00:45:51,000 --> 00:45:56,000
Now I have to say -- say,
well, what are the limits of

725
00:45:56,000 --> 00:45:57,000
integration?

726
00:45:57,000 --> 00:46:02,010
And for this Fourier series,
this function f(x) -- if I'm

727
00:46:02,010 --> 00:46:07,000
going to have -- if that right
hand side is going to be f(x),

728
00:46:07,000 --> 00:46:10,000
that function that I'm seeing
on the right,

729
00:46:10,000 --> 00:46:13,000
all those
sines and cosines,

730
00:46:13,000 --> 00:46:17,000
they're all periodic,
with -- with period two pi.

731
00:46:17,000 --> 00:46:20,000
So -- so that's what f(x) had
better be.

732
00:46:20,000 --> 00:46:23,000
So I'll integrate from zero to
two pi.

733
00:46:23,000 --> 00:46:28,000
My -- all -- everything -- is
on the interval zero two pi

734
00:46:28,000 --> 00:46:35,000
now, because if I'm going to
use these sines and cosines,

735
00:46:35,000 --> 00:46:39,000
then f(x) is equal to f(x+2pi).

736
00:46:39,000 --> 00:46:44,000
This is periodic -- periodic
functions.

737
00:46:44,000 --> 00:46:45,000
Okay.

738
00:46:45,000 --> 00:46:51,000
So now I know what -- I've got
all the right words now.

739
00:46:51,000 --> 00:47:00,000
I've got a vector space,
but the vectors are functions.

740
00:47:00,000 --> 00:47:04,000
I've got inner products and --
and the inner product gives a

741
00:47:04,000 --> 00:47:06,000
number, all right.

742
00:47:06,000 --> 00:47:09,000
It just happens to be an
integral instead of a sum.

743
00:47:09,000 --> 00:47:14,000
I've got -- and that -- then I
have the idea of orthogonality

744
00:47:14,000 --> 00:47:18,000
-- because, actually,
just -- let's just check.

745
00:47:18,000 --> 00:47:25,000
Orthogonality -- if I take the
integral -- s- I -- let me do

746
00:47:25,000 --> 00:47:32,000
sin(x) times cos(x) -- sin(x)
times cos(x) dx from zero to two

747
00:47:32,000 --> 00:47:35,000
pi -- I think we get zero.

748
00:47:35,000 --> 00:47:41,000
That's the differential of
that, so it would be one half

749
00:47:41,000 --> 00:47:45,290
sine x squared,
was that right?

750
00:47:45,290 --> 00:47:50,000
Between zero and two pi --
and, of course,

751
00:47:50,000 --> 00:47:52,000
we get zero.

752
00:47:52,000 --> 00:47:57,650
And the same would be true with
a little more -- some trig

753
00:47:57,650 --> 00:48:02,000
identities to help us out -- of
every other pair.

754
00:48:02,000 --> 00:48:07,810
So we have now an orthonormal
infinite basis for function

755
00:48:07,810 --> 00:48:13,000
space, and all we want to do is
express a function in that

756
00:48:13,000 --> 00:48:13,000
basis.
And so I --
the end of my lecture is,

757
00:48:18,000 --> 00:48:19,000
okay, what is a1?

758
00:48:19,000 --> 00:48:24,000
What's the coefficient -- how
much cos(x) is there in a

759
00:48:24,000 --> 00:48:27,000
function compared to the other
harmonics?

760
00:48:27,000 --> 00:48:31,000
How much constant is in that
function?

761
00:48:31,000 --> 00:48:35,000
That'll -- that would be an
easy question.

762
00:48:35,000 --> 00:48:39,000
The answer a0 will come out to
be the average value of f.

763
00:48:39,000 --> 00:48:42,000
That's the amount of the
constant that's in there,

764
00:48:42,000 --> 00:48:43,000
its average value.

765
00:48:43,000 --> 00:48:45,000
But let's take a1 as more
typical.

766
00:48:45,000 --> 00:48:49,000
How will I get -- here's the
end of the lecture,

767
00:48:49,000 --> 00:48:50,000
then -- how do I get a1?

768
00:48:50,000 --> 00:48:53,000
The first Fourier coefficient.

769
00:48:53,000 --> 00:48:54,000
Okay.

770
00:48:54,000 --> 00:48:57,000
I do just as I did in the
vector case.

771
00:48:57,000 --> 00:49:03,000
I take the inner product of
everything with cos(x) Take the

772
00:49:03,000 --> 00:49:06,960
inner product of everything with
cos(x).

773
00:49:06,960 --> 00:49:12,000
Then on the left -- on the left
I have -- the inner product is

774
00:49:12,000 --> 00:49:16,920
the integral of
f(x) times cos(x) cx.

775
00:49:16,920 --> 00:49:19,000
And on the right,
what do I have?

776
00:49:19,000 --> 00:49:24,000
When I -- so what I -- when I
say take the inner product with

777
00:49:24,000 --> 00:49:27,000
cos(x), let me put it in
ordinary calculus words.

778
00:49:27,000 --> 00:49:30,000
Multiply by cos(x) and
integrate.

779
00:49:30,000 --> 00:49:32,000
That's what inner products are.

780
00:49:32,000 --> 00:49:36,000
So if I multiply that whole
thing by

781
00:49:36,000 --> 00:49:41,000
cos(x) and I integrate,
I get a whole lot of zeroes.

782
00:49:41,000 --> 00:49:45,000
The only thing that survives is
that term.

783
00:49:45,000 --> 00:49:47,000
All the others disappear.

784
00:49:47,000 --> 00:49:53,000
So -- and that term is a1 times
the integral of cos(x) squared

785
00:49:53,000 --> 00:49:58,000
dx zero to 2pi equals -- so this
was the left side and this is

786
00:49:58,000 --> 00:50:03,200
all that's left on
the right-hand side.

787
00:50:03,200 --> 00:50:08,000
And this is not zero of course,
because it's the length of the

788
00:50:08,000 --> 00:50:13,000
function squared,
it's the inner product with

789
00:50:13,000 --> 00:50:18,000
itself, and -- and a simple
calculation gives that answer to

790
00:50:18,000 --> 00:50:19,000
be pi.

791
00:50:19,000 --> 00:50:23,950
So that's an easy integral and
it turns out to be pi,

792
00:50:23,950 --> 00:50:30,000
so that a1 is one over pi times
there -- times this integral.

793
00:50:30,000 --> 00:50:34,000
So there is,
actually -- that's Euler's

794
00:50:34,000 --> 00:50:39,000
famous formula for the -- or
maybe Fourier found it -- for

795
00:50:39,000 --> 00:50:43,000
the coefficients in a Fourier
series.

796
00:50:43,000 --> 00:50:48,800
And you see that it's exactly
an expansion in an orthonormal

797
00:50:48,800 --> 00:50:49,000
basis.

798
00:50:49,000 --> 00:50:51,000
Okay, thanks.

799
00:50:51,000 --> 00:50:57,000
So I'll do a quiz review on
Monday and then the quiz itself

800
00:50:57,000 --> 00:50:59,000
in Walker on Wednesday.

801
00:50:59,000 --> 00:51:01,000
Okay, see you Monday.

802
00:51:01,000 --> 00:51:04,000
Thanks.